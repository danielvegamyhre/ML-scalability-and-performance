# Session 2: Flash Attention

In session 2 we covered the original [Flash Attention paper](https://arxiv.org/pdf/2205.14135), and walked through an example Triton kernel implementation.

- [Recording](https://youtu.be/Lys0TpsLIEc?si=T1Fy8Lf874Ax0d6S)
- [Triton kernel](./flash_attention.py)